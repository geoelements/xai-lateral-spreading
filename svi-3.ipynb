{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Variable Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch.distributions as dist\n",
    "import pyro\n",
    "from pyro import optim as optim\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('xgb_models/data3.pkl', 'rb'))\n",
    "X_train_target = data['X_train_target']\n",
    "X_test_target = data['X_test_target']\n",
    "X = data['X']\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "X_val = data['X_val']\n",
    "X_all = data['X_all']\n",
    "\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "y_val = data['y_val']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6482</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2521</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2250</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5126</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2842</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5670 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target\n",
       "6482       0\n",
       "2521       1\n",
       "1691       0\n",
       "2250       0\n",
       "3880       1\n",
       "...      ...\n",
       "5126       1\n",
       "3453       1\n",
       "1690       0\n",
       "2675       1\n",
       "2842       1\n",
       "\n",
       "[5670 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Guide set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    gwd = pyro.sample('GWD', dist.Normal(0.,1.))\n",
    "    elevation = pyro.sample('Elevation', dist.Normal(0.,1.))\n",
    "    length = pyro.sample('L', dist.Normal(0.,1.))\n",
    "    slope = pyro.sample('Slope', dist.Normal(0.,1.))\n",
    "    pga = pyro.sample('PGA', dist.Normal(0.,1.))\n",
    "\n",
    "    mean= gwd * x_data[:,0] + elevation * x_data[:,1] + \\\n",
    "        length * x_data[:,2] + slope * x_data[:,3] + \\\n",
    "        pga * x_data[:,4]\n",
    "    \n",
    "    #statement pyro.sample has obs paramter in order to condition the prediction on the given data\n",
    "    with pyro.plate('data', x_data.shape[0]): #use_cuda=True\n",
    "        pyro.sample('obs', dist.Bernoulli(1/(1+torch.exp(-mean))), obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def guide(x_data, y_data):\n",
    "\n",
    "    weight_loc=pyro.param('weight_loc', torch.randn(5,device='cpu'))\n",
    "    weight_scale=pyro.param('weight_scale', torch.ones(5,device='cpu'), constraint=constraints.positive)\n",
    "    \n",
    "    gwd = pyro.sample('GWD',dist.Normal(weight_loc[0], weight_scale[0]))\n",
    "    elevation = pyro.sample('Elevation', dist.Normal(weight_loc[1], weight_scale[1]))\n",
    "    length = pyro.sample('L', dist.Normal(weight_loc[2], weight_scale[2]))\n",
    "    slope = pyro.sample('Slope', dist.Normal(weight_loc[3], weight_scale[3]))\n",
    "    pga = pyro.sample('PGA', dist.Normal(weight_loc[4], weight_scale[4]))\n",
    "\n",
    "    mean= gwd * x_data[:,0] + elevation * x_data[:,1] + \\\n",
    "        length * x_data[:,2] + slope * x_data[:,3] + \\\n",
    "        pga * x_data[:,4]    \n",
    "\n",
    "    return 1/(1+torch.exp(-mean))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(X_train.to_numpy())\n",
    "train_y = torch.tensor(y_train.to_numpy().flatten()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elbo loss: 48500.71722280979\n",
      "Elbo loss: 6494.062583684921\n",
      "Elbo loss: 21900.706865608692\n",
      "Elbo loss: 10068.860319912434\n",
      "Elbo loss: 4881.21132516861\n",
      "Elbo loss: 4824.585439503193\n",
      "Elbo loss: 4380.670043051243\n",
      "Elbo loss: 4420.653345406055\n",
      "Elbo loss: 4449.188571095467\n",
      "Elbo loss: 5421.280026972294\n",
      "Elbo loss: 6309.371141791344\n",
      "Elbo loss: 4059.818585932255\n",
      "Elbo loss: 3819.257928431034\n",
      "Elbo loss: 3927.4338613152504\n",
      "Elbo loss: 3932.9449315667152\n",
      "Elbo loss: 4126.708444714546\n",
      "Elbo loss: 5461.255423903465\n",
      "Elbo loss: 3867.670852601528\n",
      "Elbo loss: 5465.021890938282\n",
      "Elbo loss: 3929.162822186947\n",
      "Elbo loss: 3997.940897345543\n",
      "Elbo loss: 4368.146778523922\n",
      "Elbo loss: 3769.5278335809708\n",
      "Elbo loss: 4023.036661565304\n",
      "Elbo loss: 4034.970367908478\n",
      "Elbo loss: 3827.899408042431\n",
      "Elbo loss: 4274.294596731663\n",
      "Elbo loss: 4326.085002958775\n",
      "Elbo loss: 4224.467674553394\n",
      "Elbo loss: 4174.923041522503\n",
      "Elbo loss: 4047.2749814987183\n",
      "Elbo loss: 3763.570656299591\n",
      "Elbo loss: 4346.641657054424\n",
      "Elbo loss: 3772.3259114027023\n",
      "Elbo loss: 3755.4019290208817\n",
      "Elbo loss: 3797.975785791874\n",
      "Elbo loss: 4045.8997392058372\n",
      "Elbo loss: 3757.594875097275\n",
      "Elbo loss: 3766.8853157758713\n",
      "Elbo loss: 3738.3267607688904\n",
      "Elbo loss: 3818.317087650299\n",
      "Elbo loss: 3743.9155665636063\n",
      "Elbo loss: 3731.726448595524\n",
      "Elbo loss: 3939.0536035895348\n",
      "Elbo loss: 3737.1328308582306\n",
      "Elbo loss: 3736.3437206745148\n",
      "Elbo loss: 3809.5050064325333\n",
      "Elbo loss: 3906.438289165497\n",
      "Elbo loss: 3807.385123372078\n",
      "Elbo loss: 3728.694607079029\n",
      "Elbo loss: 3993.153005003929\n",
      "Elbo loss: 3790.08986222744\n",
      "Elbo loss: 3743.6126714348793\n",
      "Elbo loss: 3806.3317770957947\n",
      "Elbo loss: 3724.9012509584427\n",
      "Elbo loss: 3777.8243758678436\n",
      "Elbo loss: 3783.7767047286034\n",
      "Elbo loss: 3736.8114436864853\n",
      "Elbo loss: 3727.930496931076\n",
      "Elbo loss: 3732.7426874637604\n",
      "Elbo loss: 3740.254590511322\n",
      "Elbo loss: 3730.4766065478325\n",
      "Elbo loss: 3723.053141951561\n",
      "Elbo loss: 3758.930321276188\n",
      "Elbo loss: 3729.539268553257\n",
      "Elbo loss: 3761.071801364422\n",
      "Elbo loss: 3826.3310467600822\n",
      "Elbo loss: 3762.847143113613\n",
      "Elbo loss: 3747.142977952957\n",
      "Elbo loss: 3914.761361479759\n",
      "Elbo loss: 3722.2081826925278\n",
      "Elbo loss: 3731.9042974710464\n",
      "Elbo loss: 3738.5377218723297\n",
      "Elbo loss: 3759.660322844982\n",
      "Elbo loss: 3785.796616911888\n",
      "Elbo loss: 3819.259273827076\n",
      "Elbo loss: 3745.8812299370766\n",
      "Elbo loss: 3745.5479668974876\n",
      "Elbo loss: 3725.279898941517\n",
      "Elbo loss: 3828.18110370636\n",
      "Elbo loss: 3742.6528675556183\n",
      "Elbo loss: 3725.5381339788437\n",
      "Elbo loss: 3740.6764754652977\n",
      "Elbo loss: 3726.11968010664\n",
      "Elbo loss: 3717.7611685991287\n",
      "Elbo loss: 3776.6947360634804\n",
      "Elbo loss: 3774.9731392264366\n",
      "Elbo loss: 3807.0707099437714\n",
      "Elbo loss: 3726.1773572564125\n",
      "Elbo loss: 3754.369303524494\n",
      "Elbo loss: 3778.9486532211304\n",
      "Elbo loss: 3720.8911377191544\n",
      "Elbo loss: 3719.949565052986\n",
      "Elbo loss: 3722.3998695015907\n",
      "Elbo loss: 3720.3672345876694\n",
      "Elbo loss: 3748.45264005661\n",
      "Elbo loss: 3764.0980702638626\n",
      "Elbo loss: 3716.3711745142937\n",
      "Elbo loss: 3761.3721094727516\n",
      "Elbo loss: 3716.5645412802696\n",
      "Elbo loss: 3774.414432644844\n",
      "Elbo loss: 3744.2497052550316\n",
      "Elbo loss: 3720.105872929096\n",
      "Elbo loss: 3717.836774766445\n",
      "Elbo loss: 3720.56249833107\n",
      "Elbo loss: 3716.0774698853493\n",
      "Elbo loss: 3717.1564519405365\n",
      "Elbo loss: 3775.485152542591\n",
      "Elbo loss: 3719.3689067959785\n",
      "Elbo loss: 3767.4021345973015\n",
      "Elbo loss: 3744.0245290994644\n",
      "Elbo loss: 3791.8136612176895\n",
      "Elbo loss: 3770.0935906767845\n",
      "Elbo loss: 3716.702626824379\n",
      "Elbo loss: 3720.392910659313\n",
      "Elbo loss: 3755.2618477344513\n",
      "Elbo loss: 3732.1533172130585\n",
      "Elbo loss: 3715.361311018467\n",
      "Elbo loss: 3774.376621544361\n",
      "Elbo loss: 3719.0136479735374\n",
      "Elbo loss: 3716.6826394200325\n",
      "Elbo loss: 3719.172754406929\n",
      "Elbo loss: 3716.832125246525\n",
      "Elbo loss: 3742.330369412899\n",
      "Elbo loss: 3717.1478103995323\n",
      "Elbo loss: 3724.417722761631\n",
      "Elbo loss: 3728.077529668808\n",
      "Elbo loss: 3721.8658089637756\n",
      "Elbo loss: 3718.4201089143753\n",
      "Elbo loss: 3754.315976202488\n",
      "Elbo loss: 3715.7566641569138\n",
      "Elbo loss: 3717.6002629995346\n",
      "Elbo loss: 3721.58632004261\n",
      "Elbo loss: 3716.988813340664\n",
      "Elbo loss: 3717.7330592274666\n",
      "Elbo loss: 3802.4877629876137\n",
      "Elbo loss: 3716.629671394825\n",
      "Elbo loss: 3719.7334065437317\n",
      "Elbo loss: 3724.9789405465126\n",
      "Elbo loss: 3731.6457797288895\n",
      "Elbo loss: 3728.41991853714\n",
      "Elbo loss: 3717.5672404766083\n",
      "Elbo loss: 3716.049961388111\n",
      "Elbo loss: 3726.791223049164\n",
      "Elbo loss: 3717.19198012352\n",
      "Elbo loss: 3750.1084802746773\n",
      "Elbo loss: 3744.9204738140106\n",
      "Elbo loss: 3744.0384200811386\n",
      "Elbo loss: 3726.4920812249184\n",
      "Elbo loss: 3725.220562815666\n",
      "Elbo loss: 3722.940717935562\n",
      "Elbo loss: 3724.733636200428\n",
      "Elbo loss: 3719.4156454205513\n",
      "Elbo loss: 3715.452977657318\n",
      "Elbo loss: 3746.3368748426437\n",
      "Elbo loss: 3718.8687260746956\n",
      "Elbo loss: 3716.637647688389\n",
      "Elbo loss: 3722.9816728830338\n",
      "Elbo loss: 3717.099427521229\n",
      "Elbo loss: 3718.45808750391\n",
      "Elbo loss: 3739.316147506237\n",
      "Elbo loss: 3718.0293534994125\n",
      "Elbo loss: 3764.5819266438484\n",
      "Elbo loss: 3723.170365869999\n",
      "Elbo loss: 3717.9229586720467\n",
      "Elbo loss: 3725.2124660015106\n",
      "Elbo loss: 3724.35821390152\n",
      "Elbo loss: 3718.118926167488\n",
      "Elbo loss: 3749.0143014788628\n",
      "Elbo loss: 3726.7668979763985\n",
      "Elbo loss: 3733.08700722456\n",
      "Elbo loss: 3725.7551630735397\n",
      "Elbo loss: 3756.114131331444\n",
      "Elbo loss: 3725.3699235916138\n",
      "Elbo loss: 3722.038404762745\n",
      "Elbo loss: 3725.5912579894066\n",
      "Elbo loss: 3728.887282669544\n",
      "Elbo loss: 3736.4420213103294\n",
      "Elbo loss: 3714.823538541794\n",
      "Elbo loss: 3721.195349752903\n",
      "Elbo loss: 3716.6878914237022\n",
      "Elbo loss: 3720.2961334586143\n",
      "Elbo loss: 3724.745162963867\n",
      "Elbo loss: 3717.585436463356\n",
      "Elbo loss: 3735.6735582351685\n",
      "Elbo loss: 3720.911593079567\n",
      "Elbo loss: 3721.662610948086\n",
      "Elbo loss: 3718.9243141412735\n",
      "Elbo loss: 3749.1766297221184\n",
      "Elbo loss: 3718.8450762033463\n",
      "Elbo loss: 3734.836064040661\n",
      "Elbo loss: 3719.319056093693\n",
      "Elbo loss: 3721.599632501602\n",
      "Elbo loss: 3723.439993083477\n",
      "Elbo loss: 3716.8466697335243\n",
      "Elbo loss: 3728.6379482746124\n",
      "Elbo loss: 3770.442072570324\n",
      "Elbo loss: 3722.8914061784744\n",
      "Elbo loss: 3756.9789505004883\n",
      "Elbo loss: 3718.4779124855995\n",
      "Elbo loss: 3716.5610463023186\n",
      "Elbo loss: 3723.3314534425735\n",
      "Elbo loss: 3728.661818921566\n",
      "Elbo loss: 3725.7428760528564\n",
      "Elbo loss: 3728.558845758438\n",
      "Elbo loss: 3717.9928084015846\n",
      "Elbo loss: 3737.54130589962\n",
      "Elbo loss: 3719.2117336392403\n",
      "Elbo loss: 3717.375854074955\n",
      "Elbo loss: 3718.94300866127\n",
      "Elbo loss: 3731.976444065571\n",
      "Elbo loss: 3731.025572657585\n",
      "Elbo loss: 3716.262722671032\n",
      "Elbo loss: 3726.714060127735\n",
      "Elbo loss: 3725.129694342613\n",
      "Elbo loss: 3723.0589238405228\n",
      "Elbo loss: 3790.969339430332\n",
      "Elbo loss: 3726.6657789945602\n",
      "Elbo loss: 3769.061190843582\n",
      "Elbo loss: 3713.930849671364\n",
      "Elbo loss: 3717.935995578766\n",
      "Elbo loss: 3720.48604619503\n",
      "Elbo loss: 3717.562720119953\n",
      "Elbo loss: 3724.610219538212\n",
      "Elbo loss: 3725.9463301301003\n",
      "Elbo loss: 3717.999103605747\n",
      "Elbo loss: 3725.095081806183\n",
      "Elbo loss: 3720.825426876545\n",
      "Elbo loss: 3721.388752102852\n",
      "Elbo loss: 3722.5038944482803\n",
      "Elbo loss: 3716.4279566407204\n",
      "Elbo loss: 3725.7239892482758\n",
      "Elbo loss: 3719.2940979003906\n",
      "Elbo loss: 3737.1523789167404\n",
      "Elbo loss: 3738.0288343429565\n",
      "Elbo loss: 3727.670917212963\n",
      "Elbo loss: 3719.59443461895\n",
      "Elbo loss: 3725.849114537239\n",
      "Elbo loss: 3723.9381507635117\n",
      "Elbo loss: 3719.104574561119\n",
      "Elbo loss: 3718.7644969820976\n",
      "Elbo loss: 3718.548409640789\n",
      "Elbo loss: 3726.3739604353905\n",
      "Elbo loss: 3749.8879596590996\n",
      "Elbo loss: 3721.2458792328835\n",
      "Elbo loss: 3720.3729040026665\n",
      "Elbo loss: 3722.3182020783424\n",
      "Elbo loss: 3718.542547404766\n",
      "Elbo loss: 3728.377583503723\n",
      "Elbo loss: 3717.4457802176476\n",
      "Elbo loss: 3717.3106455802917\n",
      "Elbo loss: 3733.5803750157356\n",
      "Elbo loss: 3717.3343939185143\n",
      "Elbo loss: 3721.357708454132\n",
      "Elbo loss: 3726.7582963705063\n",
      "Elbo loss: 3717.7124017477036\n",
      "Elbo loss: 3720.0268455147743\n",
      "Elbo loss: 3734.3486496806145\n",
      "Elbo loss: 3750.2231090068817\n",
      "Elbo loss: 3754.549453496933\n",
      "Elbo loss: 3720.661083817482\n",
      "Elbo loss: 3727.357484817505\n",
      "Elbo loss: 3731.872449696064\n",
      "Elbo loss: 3719.579844534397\n",
      "Elbo loss: 3717.8931156992912\n",
      "Elbo loss: 3728.8542082309723\n",
      "Elbo loss: 3721.3630766272545\n",
      "Elbo loss: 3722.35546875\n",
      "Elbo loss: 3716.6672830581665\n",
      "Elbo loss: 3722.1700311899185\n",
      "Elbo loss: 3718.117288827896\n",
      "Elbo loss: 3730.1704853773117\n",
      "Elbo loss: 3719.3860448002815\n",
      "Elbo loss: 3720.130059361458\n",
      "Elbo loss: 3718.530562698841\n",
      "Elbo loss: 3718.241090655327\n",
      "Elbo loss: 3724.635992228985\n",
      "Elbo loss: 3729.199629366398\n",
      "Elbo loss: 3722.1153002381325\n",
      "Elbo loss: 3720.7223075032234\n",
      "Elbo loss: 3766.4540879130363\n",
      "Elbo loss: 3720.1770728826523\n",
      "Elbo loss: 3721.841916143894\n",
      "Elbo loss: 3728.783494234085\n",
      "Elbo loss: 3730.0364376306534\n",
      "Elbo loss: 3726.436646401882\n",
      "Elbo loss: 3718.4902918338776\n",
      "Elbo loss: 3741.123340845108\n",
      "Elbo loss: 3768.9071910381317\n",
      "Elbo loss: 3729.415756881237\n",
      "Elbo loss: 3744.8295710086823\n",
      "Elbo loss: 3730.7758426070213\n",
      "Elbo loss: 3752.7193143367767\n",
      "Elbo loss: 3720.472885429859\n",
      "Elbo loss: 3719.5771379470825\n",
      "Elbo loss: 3723.6376447081566\n",
      "Elbo loss: 3717.7742261886597\n",
      "Elbo loss: 3720.621406555176\n",
      "Elbo loss: 3720.988207221031\n",
      "Elbo loss: 3716.2107061743736\n"
     ]
    }
   ],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "#we have used Adam optimizer which is a wrapper on Pytorch's Adam optimizer\n",
    "#Addtionally we do not need to pass the learnable paramters explicitely like in Pytorch models. Here is happens in guide automatiaclly\n",
    "\n",
    "#jusr like  non-Bayesian Linear Regression, each iteration of our training step will take gradient step with loss as MSE\n",
    "# while in Bayesian we will use Evidence Lower Bound (ELBO) by contructing a Trace_Elbo object\n",
    "\n",
    "svi=SVI(model, guide, optim.Adam({'lr':0.06}), loss=Trace_ELBO())\n",
    "\n",
    "loss=[]\n",
    "cntr=0\n",
    "pyro.clear_param_store()\n",
    "for i in range(3000):\n",
    "    elbo=svi.step(train_x, train_y)\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(\"Elbo loss: {}\".format(elbo))\n",
    "    cntr+=1\n",
    "    loss.append(elbo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss with Iterations')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAg1ElEQVR4nO3deZRc5X3m8e/Tq1pLa23JQhJIGGGz2AYjYzlObCYwARPHMCd2rMQJyjlkNMOQiT3jTAK2k9hOmIFMYjskhgleDgJjY4JxwMRKDMKASWQUCQNCiKUBITXa96XVS1X95o/7tlzdqu6u1tbd3OdzTp269d773vu+XVI9dd+7lCICMzOzmuFugJmZjQwOBDMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzwIFg1oukZZIWDzD/dkl/cTLbdCwk/ZKkF4e7HTY6OBDspJK0XtIlw92O/kTEhyJiKYCk35X0xNGuS9JcSSGpLr0+4WGStndGz+uI+ElEvO1EbtPePBwIZqNET7CYnSgOBBsRJDVK+oqkTenxFUmNad40SQ9K2iNpl6SfSKpJ8/5Y0huS9kt6UdLFFdY9L9XtqfN1SdvK5n9L0qfS9KOSfk/SWcD/A94n6YCkPWWrnCzpn9I2n5T01ir6twT4BPBHaX0/SOWnSPqepO2SXpP0B2V1Pi/p3tS+fcDvSrpQ0orUn82S/k5SQ1r+8VT1mbSNj0u6SFJb2TrPSn3cI2mtpI+Uzbtd0lcr9U2ZL0vaJmmvpGclnTtYv210cSDYSPFZYCFwHvAu4ELgc2nep4E2oAWYAXwGCElvA34feE9ETAAuBdb3XXFEvAbsA85PRb8EHEgf+gAfAB7rU2cd8F+BFRExPiImlc3+TeALwGSgFbhhsM5FxG3AXcBfpvX9WgqoHwDPALOAi4FPSbq0rOoVwL3ApFS/CPwPYBrwvlTnv6VtfCDVeVfaxnfL2yCpPm3vR8B04L8Dd6W/42B9+5X0dzozteXjwM7B+m2jiwPBRopPAF+MiG0RsZ3sQ+l30rxuYCZwWkR0p3HxIPtwbATOllQfEesj4pV+1v8Y8EFJb0mv702v5wHNZB/K1bovIlZGRIHsQ/q8IdQt9x6gJSK+GBFdEfEq8DVgUdkyKyLiHyOiFBGHImJ1RPw0IgoRsR74e+CDVW5vITAeuDFt7xHgQbIQGKxv3cAE4O2AImJdRGw+um7bSOVAsJHiFOD1stevpzKA/0v2bfVHkl6VdB1ARLQCnwI+D2yTdLekU6jsMeAism+5jwOPkn2QfhD4SUSUhtDWLWXT7WQfskfjNOCUNHyzJw1LfYZsL6jHxvIKks5Mw2db0jDS/ybbW6jGKcDGPn19nWzvpEfFvqXw+Dvgq8BWSbdJaq5yuzZKOBBspNhE9gHZ49RURkTsj4hPR8TpwK8B/7PnWEFEfDsifjHVDeCmftb/GNlQ0UVp+gng/WSB8Fg/dY73rYD7rm8j8FpETCp7TIiIyweocyvwAjA/IprJAkRVbn8TMKfnWEpyKvBGVY2PuDkiLgDOIRs6+l9VbtdGCQeCDYd6SWPKHnXAd4DPSWqRNA34U+BbAJI+LOkMSSI7FlAEipLeJumX08HnDuBQmneEiHg5zf9t4PGI2AdsBX6d/gNhKzC756DtcbAVOL3s9UpgXzow3iSpVtK5kt4zwDomkP0NDkh6O3DNINso9yRwkOzAdr2ki8gC9u7BGi7pPZLem45DHCT7e1f8W9vo5UCw4fBDsg/nnsfngb8AVgHPAmuAp1IZwHzgYeAAsAK4JSIeJTt+cCOwg2yoYzrZN+b+PAbsjIgNZa8F/Kyf5R8B1gJbJO0YYh8r+QbZ8Y49kv4xIopkH8jnAa+R9ePrwMQB1vGHwG8B+8mON3y3z/zPA0vTNn6jfEZEdAEfAT6UtnULcFVEvFBF25vT9naTDTPtBP6qino2isg/kGNmZuA9BDMzSxwIZmYGOBDMzCxxIJiZGQBV3SxL0nqysxqKQCEiFkiaQnaGw1yy2wX8RkTsTstfD1ydlv+DiPiXVH4BcDvQRHamyScjItJpg3cAF5CdvfDxdBVmv6ZNmxZz586tvqdmZsbq1at3RERLpXlDuXvif4iI8lPvrgOWR8SN6crR64A/lnQ22aX355BdGfmwpDPTKXa3AkuAn5IFwmXAMrLw2B0RZ0haRHZx0ccHaszcuXNZtWrVEJpvZmaSXu9v3rEMGV0BLE3TS4Ery8rvjojOdFOxVuBCSTOB5ohYke5Dc0efOj3ruhe4OF2EZGZmJ0m1gRBk95FZnW7jCzCj5+ZW6Xl6Kp9F7/uvtKWyWWm6b3mvOummWnuBqUPripmZHYtqh4zeHxGbJE0HHpI00JWNlb7ZxwDlA9XpveIsjJYAnHrqqQO32MzMhqSqPYSI6LnJ2Dbg+2T3qt+ahoFIzz0/ONIGzCmrPpvsplptabpvea866b42E4FdFdpxW0QsiIgFLS0Vj4mYmdlRGjQQJI2TNKFnmuyHMp4DHgB6fox8MXB/mn4AWKTsF7Dmkd2HZmUaVtovaWE6PnBVnzo96/oo8Ej4nhpmZidVNUNGM4Dvp2O8dcC3I+KfJf07cI+kq4ENwMcAImKtpHuA54ECcG06wwiyOzPeTnba6bL0gOymX3dKaiXbMyj/gRAzMzsJRu3N7RYsWBA+7dTMbGgkrY6IBZXm5e5K5X9fv4sv/ehFugpD+YEsM7M3v9wFwlOv7+bmR1oplBwIZmblchcIZmZWmQPBzMwAB4KZmSUOBDMzAxwIZmaW5DYQRunlF2ZmJ0zuAsE31TYzqyx3gWBmZpU5EMzMDHAgmJlZ4kAwMzPAgWBmZokDwczMgBwHgi9DMDPrLXeBIHwhgplZJbkLBDMzq8yBYGZmgAPBzMwSB4KZmQEOBDMzS3IbCOH7X5uZ9ZK7QPDtr83MKstdIJiZWWUOBDMzAxwIZmaWOBDMzAxwIJiZWZLbQPBJp2ZmveU2EMzMrDcHgpmZAQ4EMzNLHAhmZgY4EMzMLHEgmJkZMIRAkFQr6WeSHkyvp0h6SNLL6Xly2bLXS2qV9KKkS8vKL5C0Js27WcpuNSepUdJ3U/mTkuYexz6amVkVhrKH8ElgXdnr64DlETEfWJ5eI+lsYBFwDnAZcIuk2lTnVmAJMD89LkvlVwO7I+IM4MvATUfVmyHw3a/NzHqrKhAkzQZ+Ffh6WfEVwNI0vRS4sqz87ojojIjXgFbgQkkzgeaIWBHZjxHc0adOz7ruBS7u2Xs43k7Qas3MRr1q9xC+AvwRUCormxERmwHS8/RUPgvYWLZcWyqblab7lveqExEFYC8wtW8jJC2RtErSqu3bt1fZdDMzq8aggSDpw8C2iFhd5TorfQWPAcoHqtO7IOK2iFgQEQtaWlqqbI6ZmVWjropl3g98RNLlwBigWdK3gK2SZkbE5jQctC0t3wbMKas/G9iUymdXKC+v0yapDpgI7DrKPpmZ2VEYdA8hIq6PiNkRMZfsYPEjEfHbwAPA4rTYYuD+NP0AsCidOTSP7ODxyjSstF/SwnR84Ko+dXrW9dG0DR/2NTM7iarZQ+jPjcA9kq4GNgAfA4iItZLuAZ4HCsC1EVFMda4BbgeagGXpAfAN4E5JrWR7BouOoV1mZnYUhhQIEfEo8Gia3glc3M9yNwA3VChfBZxbobyDFCgnjfc/zMx6yd2Vyj7p1MysstwFgpmZVeZAMDMzwIFgZmaJA8HMzAAHgpmZJQ4EMzMDchwI4QsRzMx6yV0g+O7XZmaV5S4QzMysMgeCmZkBDgQzM0scCGZmBjgQzMwsyW0g+Od3zMx6y10g+KxTM7PKchcIZmZWmQPBzMwAB4KZmSUOBDMzAxwIZmaW5DYQfNapmVlvuQsE+XanZmYV5S4QzMysMgeCmZkBDgQzM0scCGZmBjgQzMwscSCYmRmQ40AI3//azKyX3AWCL0MwM6ssd4FgZmaVORDMzAxwIJiZWeJAMDMzoIpAkDRG0kpJz0haK+kLqXyKpIckvZyeJ5fVuV5Sq6QXJV1aVn6BpDVp3s1Kd5qT1Cjpu6n8SUlzT0BfzcxsANXsIXQCvxwR7wLOAy6TtBC4DlgeEfOB5ek1ks4GFgHnAJcBt0iqTeu6FVgCzE+Py1L51cDuiDgD+DJw07F3bWA+6dTMrLdBAyEyB9LL+vQI4ApgaSpfClyZpq8A7o6Izoh4DWgFLpQ0E2iOiBWRXQRwR586Peu6F7hYJ+g+1T7r1MyssqqOIUiqlfQ0sA14KCKeBGZExGaA9Dw9LT4L2FhWvS2VzUrTfct71YmIArAXmFqhHUskrZK0avv27VV10MzMqlNVIEREMSLOA2aTfds/d4DFK30JjwHKB6rTtx23RcSCiFjQ0tIySKvNzGwohnSWUUTsAR4lG/vfmoaBSM/b0mJtwJyyarOBTal8doXyXnUk1QETgV1DaZuZmR2bas4yapE0KU03AZcALwAPAIvTYouB+9P0A8CidObQPLKDxyvTsNJ+SQvT8YGr+tTpWddHgUfCNxsyMzup6qpYZiawNJ0pVAPcExEPSloB3CPpamAD8DGAiFgr6R7geaAAXBsRxbSua4DbgSZgWXoAfAO4U1Ir2Z7BouPROTMzq96ggRARzwLnVyjfCVzcT50bgBsqlK8Cjjj+EBEdpEA5Wbz/YWbWW/6uVPbtTs3MKspfIJiZWUUOBDMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzIMeBEL4BtplZL7kLBF+FYGZWWe4CwczMKnMgmJkZ4EAwM7PEgWBmZoADwczMkvwGgs86NTPrJXeB4Ltfm5lVlrtAMDOzyhwIZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmZAjgPBlyGYmfWWu0CQb4BtZlZR7gLBzMwqcyCYmRngQDAzs8SBYGZmQI4DIQIifK6RmVmP3AbC3z/+CvOu/yH7OrqHuylmZiNC7gKh5/bX31m5AYCdB7qGsTVmZiNH7gLBzMwqcyCYmRngQDAzs8SBYGZmQBWBIGmOpB9LWidpraRPpvIpkh6S9HJ6nlxW53pJrZJelHRpWfkFktakeTdL2SFeSY2SvpvKn5Q09wT01czMBlDNHkIB+HREnAUsBK6VdDZwHbA8IuYDy9Nr0rxFwDnAZcAtkmrTum4FlgDz0+OyVH41sDsizgC+DNx0HPo2IF+CYGbW26CBEBGbI+KpNL0fWAfMAq4AlqbFlgJXpukrgLsjojMiXgNagQslzQSaI2JFZFeE3dGnTs+67gUu7tl7ON58r1Mzs8qGdAwhDeWcDzwJzIiIzZCFBjA9LTYL2FhWrS2VzUrTfct71YmIArAXmFph+0skrZK0avv27UNpupmZDaLqQJA0Hvge8KmI2DfQohXKYoDyger0Loi4LSIWRMSClpaWwZpsZmZDUFUgSKonC4O7IuK+VLw1DQORnrel8jZgTln12cCmVD67QnmvOpLqgInArqF2xszMjl41ZxkJ+AawLiK+VDbrAWBxml4M3F9WviidOTSP7ODxyjSstF/SwrTOq/rU6VnXR4FHwneeMzM7qeqqWOb9wO8AayQ9nco+A9wI3CPpamAD8DGAiFgr6R7gebIzlK6NiGKqdw1wO9AELEsPyALnTkmtZHsGi46tW2ZmNlSDBkJEPEH/J+dc3E+dG4AbKpSvAs6tUN5BCpSTzTsiZmYZX6lsZmZADgOh5+qGw6c3nZjLHczMRp3cBUJfHjIyM8vkPhDMzCyT+0DwkJGZWSb3geAhIzOzTO4DwczMMrkNhFIp2zPwkJGZWSZ3gaB0jV0hBYKHjMzMMrkLBDMzqyz3geAhIzOzTO4DwUNGZmaZ3AeCmZllch8IHjIyM8vkPhA8ZGRmlslfIHiHwMysotwFwuY9Hb1ee8jIzCyTu0D4zsoNvV57yMjMLJO7QDAzs8pyHwgeMjIzy+QuEPp+/nvIyMwsk7tA8Oe/mVlluQsEjxCZmVWWv0AY7gaYmY1QuQsEMzOrzIFgZmaAA8HMzBIHgpmZATkMBF+IZmZWWe4Coa+uYmm4m2BmNiLkPhBuffSV4W6CmdmIkPtAWPPG3uFugpnZiJD7QHh1+8HhboKZ2YiQ+0AwM7OMAyHZfbCLQ13F4W6GmdmwGTQQJH1T0jZJz5WVTZH0kKSX0/PksnnXS2qV9KKkS8vKL5C0Js27Wen8T0mNkr6byp+UNPc497Eq5//5Q3zobx4fjk2bmY0I1ewh3A5c1qfsOmB5RMwHlqfXSDobWASck+rcIqk21bkVWALMT4+edV4N7I6IM4AvAzcdbWeqMdDvH6zf2X4iN21mNqINGggR8Tiwq0/xFcDSNL0UuLKs/O6I6IyI14BW4EJJM4HmiFgR2SfyHX3q9KzrXuBincCrx0oV8qCj20NFZmZHewxhRkRsBkjP01P5LGBj2XJtqWxWmu5b3qtORBSAvcDUShuVtETSKkmrtm/fflQNL1XYQ3jdewZmZsf9oHKlb/YxQPlAdY4sjLgtIhZExIKWlpajamClPYSovDkzs1w52kDYmoaBSM/bUnkbMKdsudnAplQ+u0J5rzqS6oCJHDlEddxUOoZw31NvnKjNmZmNGkcbCA8Ai9P0YuD+svJF6cyheWQHj1emYaX9kham4wNX9anTs66PAo/EQEd+j1Gxwqpve/zVE7U5M7NRo26wBSR9B7gImCapDfgz4EbgHklXAxuAjwFExFpJ9wDPAwXg2ojoOWJ7DdkZS03AsvQA+AZwp6RWsj2DRcelZ/0oVhozMjOzwQMhIn6zn1kX97P8DcANFcpXAedWKO8gBcrJcOL2PczMRrfcXalczWhUR3fRp6KaWe4MuofwZjPYiNGP1m5hyZ2rAVh/46+ehBaZmY0MudtDqHQdQrmeMDAzyxsHgpmZAbkMhOFugZnZyJTDQHAimJlVkrtAcB6YmVWWu0A4ZeKYqpd97KWju4GemdlolLtAePvM5qqX/dJDL9G2u52fvrrzBLbIzGxkyN11CEOxbtM+fvmvHqOrWPI1CWb2ppe7QBjKffO6iqUT2BIzs5Eld0NGPqZsZlZZ7gLheHj4+a1s39853M0wMzuucjhkdGz1O7qL/N4dqzht6liuet9cfuvCU2lqqD0+jTMzG0beQ6hSqRQ898Ze3v4n/wxkv8P85w8+z03//MIxrffxl7Zz54r1x6GFZmbHJneBcPUvzjuqeoVS8OG/feKI8h0HOulOB58jglK6N8a3fvo6c6/7JwqDHJi+6psr+ZP71x5Vm8zMjqfcBcIHzmw5qnr9/dLag89uZv5nl9G67QAX//VjXPAXDwFw47Jsz6G9u0hXwWcrmdnIl7tAOFq727sGnP/0xj28uuMgu9u7eeyl7RzoLADw6vaDnPm5ZSz9t/UnoZVmZkfPgVClX7jxkQHnf+EHPx/2WfzNlYenr/zqvwLwZw+sPbyncOeK9by8df9xadeWvR2Hh6nMzI5FLgPhU5fMZ8Fpkw+//vZ/fi81OrZ17u8oDLrMmZ9bxvd/1saf3L+W//jlx9m4q/3wvH0d3QAc6Cxw/X1r2NvefXjesjWb2bK344j1bd57iIX/Zzlfefglvvb4qxzoLPAH3/kZX/1xa6/liqVgzyB7OKNFZ8E/bWp2omgoV+6OJAsWLIhVq1Yd0zrmXvdPwM9/KrO7WOLau56itkYse27LMbfxWH3ivafyTNsenntjHwBf+Mg5/NkD2Z7IrZ94N9fc9dSA9Zd/+oNs3dfBb33tSQBu+vV38MaeDs49pZk97d380fee5b984HS27Otg54Eu9nV08/XFC/jMfc9xzUVv5YmXd9BZKPKr75zJ2TOb2by3g1e3H2T9zoMc7Cxwest4zjmlmekTGvnw3z7BJxaexiVnTWf9jnYa6sT5cyZzww/Xcfk7ZtJYV8PPNuymsb6WH67ZzN8sOp/xjXUIaN1+gLENtTyzcS8AH3xbC+Maalnzxl5u+fErfOnj72LvoW5e39nOott+ygfPbOGLV5zDwc4iE8bU8cM1m5nYVM97T5/KnMlNbNrTwVsmjqG+VkhZ0r+wZR8bdx1i/vTx7DnUzar1u1j8C3OpqxHrd7Yzo7mRpvpaJNHeVWBPezdvaR5Dqs6h7iJN9bV0FkqMqc9OMy4US9TW/Hwb5Tq6i4evVWluqmd8Yx216VvHroNdTBnXAGShvr+jwJkzJlAsxeFlIoKnN+5h7tRxfO+pNi45awanTR1LRHZxZbEU1NWILfs6eEvzGIqRve7oLlFXK2olavr5lhMRSKJUil7LRAT/sLqNU6eMpVAMXtt5kN98zxx2HOhK/YTmMfU01NUcvuK/p+896+xRLAUCtuzroLmpnroaZY/amsPzC6USjXVHnrIdERRS/yTRWShSLAWNdbWH/z5Ha+eBTqaObzyivFAsIYnammx79TU17DjYyaSmBhrqfv69ufw96uguHv63UN72vv8eCsXS4X5HBN3F6HedJ4Ok1RGxoOK8PAfCD9dsZv708cyfMaHi/E98/af8a6tvbDeaTRvfSFehyL4q9uAAGmprBr1lyYzmRvYe6qajO1uueUwdNTViTF0th7qLHOrnRIJJY+tp7yzSVSxRXyvqamo41N17j2fKuAZqJHYcGNqFjzWCGolCn+HD6RMaqa+toVgKuoolOrqLFIrB1PEN7DjQSVN9LRPH1lMoBrvbuw73qVqTx9bTXQw6C0VaxjdSV1tDe1ex3/bPntwEQNvuQwDMmdJETfoA3byng4lj63td9Nn3/Thl4pjDH65dhRIHOws0N9VTKJUoFINiBJ3dJcaPqaO+RtTWilIpuw1Nz3onpoAuRfZBXCgGW/Z1UF8raiS6iqVe1yvNnDiG9q4iew91H+7D3kPd7O8oMKGxjqaGWrbt72TCmDr2dxSYNamJUmTrnDqukR0HOpk2vpHO7iLt3Vm4zWhuZEx9LV2FEpv3djChsY7G+hoiYOfBLhpqa5gyroHaGlGKoFjKQqS9q0hDbQ3XX/52rjhv1pDeqx4DBULuLkwrd/k7Zg44/67fWwjAtv0d2dcywfQJ2e2zD3UVWfX6Ln5pfgsHOgs8vWEPr+08yO6DXXQVSjQ11PLwuq2ce8pEOgtF7nvqDebPmMDYhlqe2rCbS86awUPPbwVg1qQm3thz6Ijt16j3L7w11tXQWfZBU1dz5AfA8TJ/+nhe3nbg8OszZ4znpa0HBqgxsDlTmti469ARZTsPdNHedfyGgd41eyLPtO09/Pp9b51Kfa1YtmbLER++75w9kUIxeH7zvsNlH3/PHDq6i/zD6jYmNtUTEXR0l+gqlpg5cQw7D3bxjlmTaO8q8G+vZF8Wzj6lmekTxjCmvoam+lqaGur4ycvbWbspW+8Z08cD2Yf99AmNPPjsZj78zlPY31Hg4XXZv4GFp09h9eu7ueSs6ZQCVryykzf2HOLSc2bwL2u3ctbMZqaNb2DL3g427m5nTH0tzWPq2bCrnfNPncS2fZ1MGdfAazsOHj6h4bw5k3hry3gigrpacbCryJa9HWzZ28F7T5/Cus37mT25ifGNddTViINdBZY9t6XixZtnzWzmlIljWP7CNuZNG8drOw4yeWw986aNY/yYejq6i8ya1JR9Ay4Fm/cc4qkNew7Xnz6hkTOmj2f6hOzbedvuQ0wb38AFp/586PbMGUVKpeCFLft5Y88hLjhtMuMa66gV/PjF7cye3MSF86Ycbl9E0Lr9AGfOmEB9TQ11tVmwHEof3pPHNVAsBTUSNcr2Vn7y8g4uelsLdTU1FEolapTt+ew71M2GXe3MnTqOOVPG8vrOdh5et5WFp0/h1Cljqa0RT7TuYNOeDs6bM4mO7iIPr9vGh97xFgDWbtrH22ZM4NGXtnPBaZNpqKvh5W0HmDO5iV0Huzh1yliaGmoZ21BLsQRb93Uc3sv6l7VbWfjWqUwd18Cug11s2nuIaeMbqaupYWJT/eHh7EIpaO8qUCxlX3ROhFzvIZiZ5c1Aewi5PKhsZmZHciCYmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGjOIL0yRtB14/yurTgB3HsTnDyX0Zmd4sfXmz9APclx6nRUTFH4YZtYFwLCSt6u9KvdHGfRmZ3ix9ebP0A9yXanjIyMzMAAeCmZkleQ2E24a7AceR+zIyvVn68mbpB7gvg8rlMQQzMztSXvcQzMysDweCmZkBOQwESZdJelFSq6Trhrs9g5G0XtIaSU9LWpXKpkh6SNLL6Xly2fLXp769KOnS4Ws5SPqmpG2SnisrG3LbJV2Q/gatkm5WpR8xHp6+fF7SG+m9eVrS5SO9L5LmSPqxpHWS1kr6ZCofde/LAH0Zje/LGEkrJT2T+vKFVH5y35eIyM0DqAVeAU4HGoBngLOHu12DtHk9MK1P2V8C16Xp64Cb0vTZqU+NwLzU19phbPsHgHcDzx1L24GVwPsAAcuAD42Qvnwe+MMKy47YvgAzgXen6QnAS6m9o+59GaAvo/F9ETA+TdcDTwILT/b7krc9hAuB1oh4NSK6gLuBK4a5TUfjCmBpml4KXFlWfndEdEbEa0ArWZ+HRUQ8DuzqUzyktkuaCTRHxIrI/rXfUVbnpOmnL/0ZsX2JiM0R8VSa3g+sA2YxCt+XAfrSn5Hcl4iInh8tr0+P4CS/L3kLhFnAxrLXbQz8D2gkCOBHklZLWpLKZkTEZsj+UwDTU/lo6N9Q2z4rTfctHyl+X9KzaUipZ3d+VPRF0lzgfLJvo6P6fenTFxiF74ukWklPA9uAhyLipL8veQuESmNpI/282/dHxLuBDwHXSvrAAMuOxv716K/tI7lPtwJvBc4DNgN/ncpHfF8kjQe+B3wqIvYNtGiFspHel1H5vkREMSLOA2aTfds/d4DFT0hf8hYIbcCcstezgU3D1JaqRMSm9LwN+D7ZENDWtGtIet6WFh8N/Rtq29vSdN/yYRcRW9N/4hLwNX4+PDei+yKpnuwD9K6IuC8Vj8r3pVJfRuv70iMi9gCPApdxkt+XvAXCvwPzJc2T1AAsAh4Y5jb1S9I4SRN6poFfAZ4ja/PitNhi4P40/QCwSFKjpHnAfLIDTCPJkNqedpP3S1qYzpa4qqzOsOr5j5r8J7L3BkZwX9J2vwGsi4gvlc0ade9Lf30Zpe9Li6RJaboJuAR4gZP9vpzMI+kj4QFcTnY2wivAZ4e7PYO09XSyMwmeAdb2tBeYCiwHXk7PU8rqfDb17UWG4WycPu3/DtkuezfZN5erj6btwAKy/9SvAH9HusJ+BPTlTmAN8Gz6DzpzpPcF+EWyIYRngafT4/LR+L4M0JfR+L68E/hZavNzwJ+m8pP6vvjWFWZmBuRvyMjMzPrhQDAzM8CBYGZmiQPBzMwAB4KZmSUOBDMzAxwIZmaW/H/8HfOkpDVzHgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(cntr),loss)\n",
    "plt.title(\"Loss with Iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0),\n",
    "            \"std\": torch.std(v, 0),\n",
    "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "        }\n",
    "    return site_stats\n",
    "\n",
    "predictive = Predictive(model, guide=guide, num_samples=800)\n",
    "samples = predictive(train_x, train_y)\n",
    "pred_summary = summary(samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['GWD', 'Elevation', 'L', 'Slope', 'PGA']:\n",
    "    for p in pred_summary[k].keys():\n",
    "        pred_summary[k][p]=pred_summary[k][p].item()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GWD</th>\n",
       "      <th>Elevation</th>\n",
       "      <th>L</th>\n",
       "      <th>Slope</th>\n",
       "      <th>PGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.390886</td>\n",
       "      <td>0.048609</td>\n",
       "      <td>-0.663129</td>\n",
       "      <td>0.037956</td>\n",
       "      <td>2.062912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.015533</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.027749</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>0.070904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>-0.414836</td>\n",
       "      <td>0.028161</td>\n",
       "      <td>-0.707219</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>1.949839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>-0.364889</td>\n",
       "      <td>0.070276</td>\n",
       "      <td>-0.617590</td>\n",
       "      <td>0.067781</td>\n",
       "      <td>2.178674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           GWD  Elevation         L     Slope       PGA\n",
       "mean -0.390886   0.048609 -0.663129  0.037956  2.062912\n",
       "std   0.015533   0.012623  0.027749  0.019110  0.070904\n",
       "5%   -0.414836   0.028161 -0.707219  0.007895  1.949839\n",
       "95%  -0.364889   0.070276 -0.617590  0.067781  2.178674"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary=pd.DataFrame(pred_summary)\n",
    "summary.drop('obs',axis=1,inplace=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = torch.tensor(X_test.to_numpy())\n",
    "test_y = torch.tensor(y_test.to_numpy().flatten()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i in range(len(test_y)):\n",
    "    pred = guide(test_x,None).detach().cpu().numpy()\n",
    "    #pred = sampled_reg_model(test_x,None)\n",
    "    preds.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.017251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean       std\n",
       "0        1  0.014508\n",
       "1        0  0.026381\n",
       "2        1  0.017251\n",
       "3        1  0.016797\n",
       "4        1  0.015863\n",
       "...    ...       ...\n",
       "1058     1  0.015011\n",
       "1059     0  0.016010\n",
       "1060     0  0.019710\n",
       "1061     1  0.013765\n",
       "1062     1  0.021970\n",
       "\n",
       "[1063 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=np.stack(preds).T\n",
    "preds_mean=preds.mean(axis=1)\n",
    "preds_med=preds.std(axis=1)\n",
    "\n",
    "predc=pd.concat([pd.DataFrame(preds_mean),pd.DataFrame(preds_med)],axis=1)\n",
    "predc.columns=['mean','std']\n",
    "predc['mean']=np.where(predc['mean']>0.45,1,0)\n",
    "predc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "predc['Actual'] = test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.026381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.017251</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015863</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>1</td>\n",
       "      <td>0.015011</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0</td>\n",
       "      <td>0.016010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>0</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0.013765</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.021970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1063 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean       std  Actual\n",
       "0        1  0.014508     0.0\n",
       "1        0  0.026381     0.0\n",
       "2        1  0.017251     0.0\n",
       "3        1  0.016797     1.0\n",
       "4        1  0.015863     0.0\n",
       "...    ...       ...     ...\n",
       "1058     1  0.015011     1.0\n",
       "1059     0  0.016010     0.0\n",
       "1060     0  0.019710     1.0\n",
       "1061     1  0.013765     0.0\n",
       "1062     1  0.021970     0.0\n",
       "\n",
       "[1063 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %2.f%%\" % (100* (1- np.sum(np.abs(predc['mean'] - predc['Actual']))/len(y_test))))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a15fe14c9164b2c84764451972c480ab7caecb14ffdaafbc4f746bd44fda90e1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('xai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
